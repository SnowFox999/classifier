{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41fe8a88-3d58-47f1-82b3-0dfc0b4ce948",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12882 2279 2478 3632 642 755\n",
      "TRAIN class distribution:\n",
      "label\n",
      "0    2697\n",
      "1     129\n",
      "2     471\n",
      "3    2904\n",
      "4    4119\n",
      "5     227\n",
      "6     918\n",
      "7     214\n",
      "8     793\n",
      "9     410\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Support for `validation_epoch_end` has been removed in v2.0.0. `EfficientNetLit` implements this method. You can use the `on_validation_epoch_end` hook instead. To access outputs, save them in-memory as instance attributes. You can find migration examples in https://github.com/Lightning-AI/pytorch-lightning/pull/16520.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 98\u001b[39m\n\u001b[32m     94\u001b[39m     trainer.fit(model, datamodule=datamodule)\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 94\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     70\u001b[39m early_stop = pl.callbacks.EarlyStopping(\n\u001b[32m     71\u001b[39m     monitor=\u001b[33m\"\u001b[39m\u001b[33mval_balanced_acc\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     72\u001b[39m     patience=\u001b[32m20\u001b[39m,\n\u001b[32m     73\u001b[39m     mode=\u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     74\u001b[39m     verbose=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     75\u001b[39m )\n\u001b[32m     78\u001b[39m trainer = pl.Trainer(\n\u001b[32m     79\u001b[39m     max_epochs=EPOCHS,\n\u001b[32m     80\u001b[39m     accelerator=\u001b[33m\"\u001b[39m\u001b[33mgpu\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     91\u001b[39m     ],\n\u001b[32m     92\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:584\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path, weights_only)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    583\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m584\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    586\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    587\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:49\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     52\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:630\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path, weights_only)\u001b[39m\n\u001b[32m    623\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    624\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    625\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    626\u001b[39m     ckpt_path,\n\u001b[32m    627\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    628\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    629\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    633\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1027\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path, weights_only)\u001b[39m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28mself\u001b[39m._callback_connector._attach_model_callbacks()\n\u001b[32m   1025\u001b[39m \u001b[38;5;28mself\u001b[39m._callback_connector._attach_model_logging_functions()\n\u001b[32m-> \u001b[39m\u001b[32m1027\u001b[39m \u001b[43m_verify_loop_configurations\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1030\u001b[39m \u001b[38;5;66;03m# SET UP THE TRAINER\u001b[39;00m\n\u001b[32m   1031\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1032\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: setting up strategy environment\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:36\u001b[39m, in \u001b[36m_verify_loop_configurations\u001b[39m\u001b[34m(trainer)\u001b[39m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnexpected: Trainer state fn must be set before validating loop configuration.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.state.fn == TrainerFn.FITTING:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[43m__verify_train_val_loop_configuration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     __verify_manual_optimization_support(trainer, model)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m trainer.state.fn == TrainerFn.VALIDATING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:84\u001b[39m, in \u001b[36m__verify_train_val_loop_configuration\u001b[39m\u001b[34m(trainer, model)\u001b[39m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m     78\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSupport for `training_epoch_end` has been removed in v2.0.0. `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` implements this\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     79\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m method. You can use the `on_train_epoch_end` hook instead. To access outputs, save them in-memory as\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     80\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m instance attributes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     81\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m You can find migration examples in https://github.com/Lightning-AI/pytorch-lightning/pull/16520.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     82\u001b[39m     )\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(model, \u001b[33m\"\u001b[39m\u001b[33mvalidation_epoch_end\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m     85\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSupport for `validation_epoch_end` has been removed in v2.0.0. `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` implements this\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     86\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m method. You can use the `on_validation_epoch_end` hook instead. To access outputs, save them in-memory as\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     87\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m instance attributes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     88\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m You can find migration examples in https://github.com/Lightning-AI/pytorch-lightning/pull/16520.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     89\u001b[39m     )\n",
      "\u001b[31mNotImplementedError\u001b[39m: Support for `validation_epoch_end` has been removed in v2.0.0. `EfficientNetLit` implements this method. You can use the `on_validation_epoch_end` hook instead. To access outputs, save them in-memory as instance attributes. You can find migration examples in https://github.com/Lightning-AI/pytorch-lightning/pull/16520."
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "\n",
    "from config import *\n",
    "from utils.seed import set_seed\n",
    "from data.splits import create_splits\n",
    "from data.transforms import get_transforms\n",
    "from data.datamodule import ImageDataModule\n",
    "from models.efficientnet import EfficientNetLit\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "import torch\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "from utils.make_sampler import make_sampler\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    set_seed(SEED)\n",
    "\n",
    "    train_df, val_df, test_df, classes = create_splits(\n",
    "        metadata_csv= METADATA_DIR,\n",
    "        images_dir= METADATA_DIR,\n",
    "        seed=SEED,\n",
    "        test_size=TEST_SIZE,\n",
    "        val_size=VAL_SIZE,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        len(train_df),\n",
    "        len(val_df),\n",
    "        len(test_df),\n",
    "        train_df.lesion_id.nunique(),\n",
    "        val_df.lesion_id.nunique(),\n",
    "        test_df.lesion_id.nunique(),\n",
    "    )\n",
    "\n",
    "    print(\"TRAIN class distribution:\")\n",
    "    print(train_df[\"label\"].value_counts().sort_index())\n",
    "    \n",
    "    train_sampler = make_sampler(train_df[\"label\"].values)\n",
    "\n",
    "    train_tfms, val_tfms = get_transforms()\n",
    "\n",
    "    datamodule = ImageDataModule(\n",
    "        train_df=train_df,\n",
    "        val_df=val_df,\n",
    "        test_df=test_df,\n",
    "        train_tfms=train_tfms,\n",
    "        val_tfms=val_tfms,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        train_sampler=train_sampler,\n",
    "     )\n",
    "\n",
    "    model = EfficientNetLit(\n",
    "        num_classes=len(classes),\n",
    "        lr=LR,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "    )\n",
    "\n",
    "\n",
    "    logger = CSVLogger(\"logs\", name=\"efficientnet\")\n",
    "\n",
    "    early_stop = pl.callbacks.EarlyStopping(\n",
    "        monitor=\"val_balanced_acc\",\n",
    "        patience=20,\n",
    "        mode=\"max\",\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=EPOCHS,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        logger=logger,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(\n",
    "                monitor=\"val_balanced_acc\",\n",
    "                mode=\"max\",\n",
    "                save_top_k=1,\n",
    "                filename=\"epoch{epoch}-recall{val_macro_recall:.4f}\",\n",
    "            ),\n",
    "            early_stop,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baae7a31-851a-456d-84c2-47140d88cf04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-env]",
   "language": "python",
   "name": "conda-env-.conda-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
